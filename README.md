***Automated Queen Bee Detection from Beehive Sounds***
- This project uses Artificial Intelligence to listen to the sounds inside a beehive and automatically determine if a queen bee is present. Knowing the queen's status is vital for beekeepers, as she is crucial for a healthy and productive colony, but manual checks are disruptive. Our system offers a non-invasive alternative.
-  We start with beehive audio recordings. These are processed into short 2-second chunks. Using the Librosa library, we extract two types of sound "fingerprints" (features) from these chunks: detailed Mel-Spectrograms (like sound images) and more compressed MFCCs. To make our AI model more robust, we augment the training audio by adding slight noise and pitch shifts; for Mel-Spectrograms, we also apply SpecAugment (masking parts of the sound image).
   - A Convolutional Neural Network (CNN), built with TensorFlow/Keras, learns to distinguish between sounds from hives with and without a queen. This "brain" of our system uses layers designed to find important patterns in the sound features.
   - The model trained on augmented Mel-Spectrograms performed best, achieving 99.71% accuracy on a standard test set. To test how well it works on completely new hives, "Leave-One-Out Cross-Validation".
   - You can use the provided Jupyter Notebook (queen_bee_classifier_v2.ipynb) to replicate this process and the Streamlit app (app_v2.py) for live predictions. (Ensure you configure config_v2.py and how hive IDs are extracted from your filenames for full functionality.)
